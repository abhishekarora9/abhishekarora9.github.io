import os
import uuid
import shutil
import json
from datetime import datetime
from fastapi import FastAPI, UploadFile, File, Body, Form, Request, BackgroundTasks, HTTPException, Depends
from fastapi.responses import FileResponse, JSONResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

# Import our modular components
from config import CORS_ORIGINS, S3_RESULTS_MAP, save_s3_results_map
from services.file_processor import start_processing, get_job_status, get_job
from services.chat_service import chat_with_file
from utils.s3_utils import upload_to_s3, download_output_from_s3, list_results_structure, list_s3_files, S3_BUCKET
from utils.llm_utils import extract_xml_content
import re
import boto3

def add_bpmn_watermark(content):
    """Add a watermark to BPMN XML content"""
    watermark_comment = f"""
    <!-- 
    ========================================
    BPMN Generated by Abhishek Arora
    BPMN Generator - Professional Workflow Design
    Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    ========================================
    -->
    """
    
    # Find the opening <bpmn:definitions> tag and add watermark after it
    if '<bpmn:definitions' in content:
        # Add watermark after the opening definitions tag
        content = re.sub(
            r'(<bpmn:definitions[^>]*>)',
            r'\1' + watermark_comment,
            content,
            count=1
        )
    elif '<definitions' in content:
        # Add watermark after the opening definitions tag (without namespace)
        content = re.sub(
            r'(<definitions[^>]*>)',
            r'\1' + watermark_comment,
            content,
            count=1
        )
    
    return content

app = FastAPI()

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security scheme for authentication
security = HTTPBearer()

# Authentication functions
def get_allowed_users():
    """Fetch allowed users from S3"""
    try:
        s3_client = boto3.client('s3')
        response = s3_client.get_object(Bucket=S3_BUCKET, Key='auth/allowed_users.json')
        users_data = json.loads(response['Body'].read().decode('utf-8'))
        return users_data.get('users', [])
    except Exception as e:
        print(f"Error fetching allowed users: {e}")
        # Return empty list if file doesn't exist or error occurs
        return []

def get_access_requests():
    """Fetch access requests from S3"""
    try:
        s3_client = boto3.client('s3')
        response = s3_client.get_object(Bucket=S3_BUCKET, Key='auth/access_requests.json')
        requests_data = json.loads(response['Body'].read().decode('utf-8'))
        return requests_data.get('requests', [])
    except Exception as e:
        print(f"Error fetching access requests: {e}")
        # Return empty list if file doesn't exist or error occurs
        return []

def save_access_requests(requests_list):
    """Save access requests to S3"""
    try:
        s3_client = boto3.client('s3')
        requests_data = {"requests": requests_list}
        s3_client.put_object(
            Bucket=S3_BUCKET,
            Key='auth/access_requests.json',
            Body=json.dumps(requests_data, indent=2),
            ContentType='application/json'
        )
        return True
    except Exception as e:
        print(f"Error saving access requests: {e}")
        return False

def verify_user(ads_id: str, password: str):
    """Verify user credentials against allowed users list"""
    allowed_users = get_allowed_users()
    for user in allowed_users:
        if user.get('ads_id') == ads_id and user.get('password') == password:
            return user
    return None

def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Dependency to get current authenticated user"""
    try:
        # For simplicity, we'll use the token as ads_id
        # In a real implementation, you'd verify JWT tokens
        ads_id = credentials.credentials
        allowed_users = get_allowed_users()
        
        # Check if ads_id exists in allowed users
        for user in allowed_users:
            if user.get('ads_id') == ads_id:
                return ads_id
        
        raise HTTPException(status_code=401, detail="Invalid credentials")
    except Exception as e:
        raise HTTPException(status_code=401, detail="Invalid credentials")

# Initialize auth files in S3 if they don't exist
def initialize_auth_files():
    """Initialize the auth files in S3 if they don't exist"""
    try:
        s3_client = boto3.client('s3')
        
        # Initialize allowed users file
        try:
            s3_client.head_object(Bucket=S3_BUCKET, Key='auth/allowed_users.json')
            print("Auth file already exists in S3")
        except:
            # Create empty users file
            default_users = {
                "users": []
            }
            
            # Upload to S3
            s3_client.put_object(
                Bucket=S3_BUCKET,
                Key='auth/allowed_users.json',
                Body=json.dumps(default_users, indent=2),
                ContentType='application/json'
            )
            print("Initialized auth file in S3")
        
        # Initialize access requests file
        try:
            s3_client.head_object(Bucket=S3_BUCKET, Key='auth/access_requests.json')
            print("Access requests file already exists in S3")
        except:
            # Create empty requests file
            default_requests = {
                "requests": []
            }
            
            # Upload to S3
            s3_client.put_object(
                Bucket=S3_BUCKET,
                Key='auth/access_requests.json',
                Body=json.dumps(default_requests, indent=2),
                ContentType='application/json'
            )
            print("Initialized access requests file in S3")
        
    except Exception as e:
        print(f"Error initializing auth files: {e}")

# Initialize auth files on startup
initialize_auth_files()

@app.post("/login")
def login(ads_id: str = Body(...), password: str = Body(...)):
    """Authenticate user and return token"""
    user = verify_user(ads_id, password)
    if user:
        # For simplicity, we'll use ads_id as token
        # In a real implementation, you'd generate JWT tokens
        return {
            "token": ads_id, 
            "ads_id": ads_id, 
            "role": user.get('role', 'user'),
            "message": "Login successful"
        }
    else:
        raise HTTPException(status_code=401, detail="Invalid credentials")

@app.get("/auth/status")
def auth_status(current_user: str = Depends(get_current_user)):
    """Check if user is authenticated"""
    allowed_users = get_allowed_users()
    user_role = "user"  # default role
    
    # Find user role
    for user in allowed_users:
        if user.get('ads_id') == current_user:
            user_role = user.get('role', 'user')
            break
    
    return {"authenticated": True, "ads_id": current_user, "role": user_role}

@app.get("/auth/users")
def get_users(current_user: str = Depends(get_current_user)):
    """Get list of allowed users (admin only)"""
    allowed_users = get_allowed_users()
    # Return only ads_ids and roles, not passwords
    safe_users = []
    for user in allowed_users:
        safe_users.append({
            "ads_id": user.get("ads_id"),
            "role": user.get("role"),
            "created_at": user.get("created_at")
        })
    return {"users": safe_users}

@app.post("/auth/request-access")
def request_access(ads_id: str = Body(...), password: str = Body(...)):
    """Submit an access request"""
    try:
        # Check if user already exists
        allowed_users = get_allowed_users()
        for user in allowed_users:
            if user.get('ads_id') == ads_id:
                raise HTTPException(status_code=400, detail="User already has access")
        
        # Check if request already exists
        existing_requests = get_access_requests()
        for request in existing_requests:
            if request.get('ads_id') == ads_id:
                raise HTTPException(status_code=400, detail="Access request already submitted")
        
        # Add new request
        new_request = {
            "ads_id": ads_id,
            "password": password,
            "status": "pending",
            "requested_at": datetime.now().isoformat()
        }
        
        existing_requests.append(new_request)
        
        if save_access_requests(existing_requests):
            return {"message": "Access request submitted successfully", "ads_id": ads_id}
        else:
            raise HTTPException(status_code=500, detail="Failed to save access request")
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error submitting request: {str(e)}")

@app.get("/auth/access-requests")
def get_access_requests_endpoint(current_user: str = Depends(get_current_user)):
    """Get list of access requests (admin only)"""
    requests = get_access_requests()
    # Return requests without passwords for security
    safe_requests = []
    for request in requests:
        safe_requests.append({
            "ads_id": request.get("ads_id"),
            "status": request.get("status"),
            "requested_at": request.get("requested_at")
        })
    return {"requests": safe_requests}

@app.post("/auth/approve-request")
def approve_request(ads_id: str = Body(...), current_user: str = Depends(get_current_user)):
    """Approve an access request and add user to allowed users"""
    try:
        # Get the request
        requests = get_access_requests()
        target_request = None
        
        for request in requests:
            if request.get('ads_id') == ads_id and request.get('status') == 'pending':
                target_request = request
                break
        
        if not target_request:
            raise HTTPException(status_code=404, detail="Request not found or already processed")
        
        # Add user to allowed users
        allowed_users = get_allowed_users()
        new_user = {
            "ads_id": target_request['ads_id'],
            "password": target_request['password'],
            "role": "user",
            "created_at": datetime.now().isoformat()
        }
        
        allowed_users.append(new_user)
        
        # Save updated allowed users
        s3_client = boto3.client('s3')
        users_data = {"users": allowed_users}
        s3_client.put_object(
            Bucket=S3_BUCKET,
            Key='auth/allowed_users.json',
            Body=json.dumps(users_data, indent=2),
            ContentType='application/json'
        )
        
        # Update request status
        for request in requests:
            if request.get('ads_id') == ads_id:
                request['status'] = 'approved'
                request['approved_at'] = datetime.now().isoformat()
                request['approved_by'] = current_user
                break
        
        save_access_requests(requests)
        
        return {"message": f"User {ads_id} approved successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error approving request: {str(e)}")

@app.post("/auth/reject-request")
def reject_request(ads_id: str = Body(...), current_user: str = Depends(get_current_user)):
    """Reject an access request"""
    try:
        requests = get_access_requests()
        
        # Update request status
        for request in requests:
            if request.get('ads_id') == ads_id and request.get('status') == 'pending':
                request['status'] = 'rejected'
                request['rejected_at'] = datetime.now().isoformat()
                request['rejected_by'] = current_user
                break
        else:
            raise HTTPException(status_code=404, detail="Request not found or already processed")
        
        save_access_requests(requests)
        
        return {"message": f"Request for {ads_id} rejected successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error rejecting request: {str(e)}")

@app.post("/upload")
def upload(file: UploadFile = File(...), current_user: str = Depends(get_current_user)):
    """Upload a new file for processing"""
    job_id = str(uuid.uuid4())
    
    # Create temporary file for S3 upload
    temp_file_path = os.path.join("/tmp", f"{job_id}_{file.filename}")
    
    with open(temp_file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    # Upload to S3
    bucket = S3_BUCKET
    s3_key = f"{job_id}_{file.filename}"
    upload_to_s3(temp_file_path, bucket, s3_key)
    
    # Start processing with S3 key only
    start_processing(job_id, s3_key, bucket, s3_key)
    
    # Clean up temp file
    os.remove(temp_file_path)
    
    return {"job_id": job_id}

@app.post("/process_existing")
def process_existing(s3_key: str = Body(..., embed=True), current_user: str = Depends(get_current_user)):
    """Process an existing file from S3"""
    try:
        # Check if results for this S3 key already exist in S3
        expected_outputs = [
            ("extracted_text_s3_key", "extracted_text.txt"),
            ("bpmn_template_s3_key", "bpmn_template.json"),
            ("refined_bpmn_template_s3_key", "refined_bpmn_template.json"),
            ("bpmn_xml_s3_key", "bpmn_xml.xml"),
            ("final_bpmn_xml_s3_key", "final_bpmn_xml.bpmn"),
            ("summary_s3_key", "summary.txt"),
            ("result_s3_key", "result.bpmn.xml")
        ]
        
        job_id = None
        all_found = True
        s3_keys = {}
        
        for key, output_name in expected_outputs:
            s3_key_path = f"results/{s3_key}/{output_name}"
            # Check if file exists in S3
            import boto3
            s3_client = boto3.client('s3')
            try:
                s3_client.head_object(Bucket=S3_BUCKET, Key=s3_key_path)
                s3_keys[key] = s3_key_path
            except:
                all_found = False
        
        if all_found:
            # Use a deterministic job_id for this s3_key for reuse
            job_id = f"s3_{s3_key.replace('/', '_')}"
            job = {"status": "completed", "s3_key": s3_key, "bucket": S3_BUCKET}
            for key, s3_key_path in s3_keys.items():
                job[key] = s3_key_path
            
            # Import here to avoid circular imports
            from services.file_processor import JOBS
            JOBS[job_id] = job
            return {"job_id": job_id, "reused": True}
        
        # If not all outputs found, process as usual
        job_id = str(uuid.uuid4())
        
        # Start processing with S3 key only (no local file needed)
        start_processing(job_id, s3_key, S3_BUCKET, s3_key)
        
        # Save mapping for future reuse
        S3_RESULTS_MAP[s3_key] = job_id
        save_s3_results_map()
        
        return {"job_id": job_id, "reused": False}
        
    except Exception as e:
        print(f"[process_existing] Error: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/reprocess")
def reprocess(s3_key: str = Body(..., embed=True), current_user: str = Depends(get_current_user)):
    """Reprocess an existing file from S3 and replace previous outputs"""
    try:
        print(f"[reprocess] Starting reprocessing for S3 key: {s3_key}")
        
        # Generate a new job ID for reprocessing
        job_id = str(uuid.uuid4())
        
        # Start processing with S3 key (this will overwrite existing outputs)
        start_processing(job_id, s3_key, S3_BUCKET, s3_key)
        
        # Save mapping for future reuse
        S3_RESULTS_MAP[s3_key] = job_id
        save_s3_results_map()
        
        print(f"[reprocess] Started reprocessing job {job_id} for {s3_key}")
        return {"job_id": job_id, "action": "reprocessing", "s3_key": s3_key}
        
    except Exception as e:
        print(f"[reprocess] Error: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/reprocess_batch")
def reprocess_batch(s3_keys: list = Body(..., embed=True), current_user: str = Depends(get_current_user)):
    """Reprocess multiple existing files from S3 and replace previous outputs"""
    try:
        print(f"[reprocess_batch] Starting batch reprocessing for {len(s3_keys)} files")
        
        job_ids = []
        
        for s3_key in s3_keys:
            # Generate a new job ID for each reprocessing
            job_id = str(uuid.uuid4())
            
            # Start processing with S3 key (this will overwrite existing outputs)
            start_processing(job_id, s3_key, S3_BUCKET, s3_key)
            
            # Save mapping for future reuse
            S3_RESULTS_MAP[s3_key] = job_id
            save_s3_results_map()
            
            job_ids.append({"job_id": job_id, "s3_key": s3_key})
            print(f"[reprocess_batch] Started reprocessing job {job_id} for {s3_key}")
        
        print(f"[reprocess_batch] Started {len(job_ids)} reprocessing jobs")
        return {"jobs": job_ids, "action": "batch_reprocessing", "total_files": len(s3_keys)}
        
    except Exception as e:
        print(f"[reprocess_batch] Error: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/status/{job_id}")
def status(job_id: str, current_user: str = Depends(get_current_user)):
    """Get the status of a processing job"""
    job = get_job_status(job_id)
    if not job:
        return JSONResponse(status_code=404, content={"status": "not_found"})
    return {"status": job["status"]}

@app.get("/download/{job_id}")
def download(job_id: str, background_tasks: BackgroundTasks):
    """Download the final BPMN file from S3"""
    job = get_job(job_id)
    if not job or job["status"] != "completed":
        return JSONResponse(status_code=404, content={"error": "Not ready"})
    
    # Get S3 key for the result file
    s3_key = job.get("result_s3_key")
    if not s3_key:
        return JSONResponse(status_code=404, content={"error": "Result not found"})
    
    bpmn_filename = f"bpmn_{job_id}.bpmn"
    
    # Download from S3 to temp file
    temp_file_path = os.path.join("/tmp", f"{job_id}_result.bpmn")
    try:
        # Download from S3
        import boto3
        s3_client = boto3.client('s3')
        s3_client.download_file(S3_BUCKET, s3_key, temp_file_path)
        
        # Check if file needs cleaning
        with open(temp_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # If content contains explanatory text, clean it
        if content.find('Certainly!') != -1 or content.find('**refined, deployment-ready BPMN 2.0 XML**') != -1:
            clean_content = extract_xml_content(content)
            content = clean_content
            print(f"[download] Cleaned BPMN file for job {job_id}")
        

        
        # Add watermark to BPMN files
        content = add_bpmn_watermark(content)
        
        # Write the watermarked content back to temp file
        with open(temp_file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"[download] Added watermark to BPMN file for job {job_id}")
        
        # Add cleanup task to background
        def cleanup_temp_file():
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
        
        background_tasks.add_task(cleanup_temp_file)
        
        return FileResponse(temp_file_path, filename=bpmn_filename)
        
    except Exception as e:
        # Clean up temp file on error
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        print(f"[download] Error downloading BPMN file for job {job_id}: {e}")
        return JSONResponse(status_code=500, content={"error": "Failed to download file"})

@app.get("/download/{job_id}/{output_type}")
def download_intermediate(job_id: str, output_type: str, background_tasks: BackgroundTasks):
    """Download intermediate output files from S3"""
    job = get_job(job_id)
    if not job or job["status"] not in ["completed", "processing"]:
        return JSONResponse(status_code=404, content={"error": "Not ready"})
    
    # Get S3 key for the output file
    s3_key = job.get(f"{output_type}_s3_key")
    if not s3_key:
        return JSONResponse(status_code=404, content={"error": f"{output_type} not available"})
    
    # Determine file extension
    ext_map = {
        "extracted_text": ".txt",
        "bpmn_template": ".json",
        "refined_bpmn_template": ".json",
        "bpmn_xml": ".xml",
        "final_bpmn_xml": ".bpmn",
        "summary": ".txt"
    }
    ext = ext_map.get(output_type, ".txt")
    filename = f"{output_type}_{job_id}{ext}"
    
    # Download from S3 to temp file
    temp_file_path = os.path.join("/tmp", f"{job_id}_{output_type}{ext}")
    try:
        # Download from S3
        import boto3
        s3_client = boto3.client('s3')
        s3_client.download_file(S3_BUCKET, s3_key, temp_file_path)
        
        # Check if this is a BPMN file that needs cleaning
        if output_type in ["bpmn_xml", "final_bpmn_xml"]:
            try:
                with open(temp_file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # If content contains explanatory text, clean it
                if content.find('Certainly!') != -1 or content.find('**refined, deployment-ready BPMN 2.0 XML**') != -1:
                    clean_content = extract_xml_content(content)
                    content = clean_content
                    print(f"[download_intermediate] Cleaned {output_type} file for job {job_id}")
                

                
                # Add watermark to BPMN files
                content = add_bpmn_watermark(content)
                
                # Write the watermarked content back to temp file
                with open(temp_file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"[download_intermediate] Added watermark to {output_type} file for job {job_id}")
            except Exception as e:
                print(f"[download_intermediate] Error cleaning {output_type} file for job {job_id}: {e}")
        
        # Add cleanup task to background
        def cleanup_temp_file():
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
        
        background_tasks.add_task(cleanup_temp_file)
        
        return FileResponse(temp_file_path, filename=filename)
        
    except Exception as e:
        # Clean up temp file on error
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        print(f"[download_intermediate] Error downloading {output_type} file for job {job_id}: {e}")
        return JSONResponse(status_code=500, content={"error": "Failed to download file"})

@app.post("/chat")
def chat(job_id: str = Body(...), prompt: str = Body(...), current_user: str = Depends(get_current_user)):
    """Chat with a processed file"""
    job = get_job(job_id)
    return chat_with_file(job_id, prompt, job)

@app.get("/files")
def list_files(current_user: str = Depends(get_current_user)):
    """List all files in S3 bucket"""
    return list_s3_files()

@app.get("/job_outputs/{job_id}")
def job_outputs(job_id: str, request: Request):
    """Get all outputs for a job with HTML or JSON response"""
    job = get_job(job_id)
    if not job:
        if "text/html" in request.headers.get("accept", ""):
            return HTMLResponse(f"<h2>Job not found</h2>")
        return JSONResponse(status_code=404, content={"error": "Job not found"})
    
    outputs = {}
    for key in [
        "extracted_text_s3_key",
        "bpmn_template_s3_key",
        "refined_bpmn_template_s3_key",
        "bpmn_xml_s3_key",
        "final_bpmn_xml_s3_key",
        "summary_s3_key",
        "result_s3_key"
    ]:
        if key in job:
            outputs[key] = job[key]
    
    status = job.get("status")
    source_file = job.get("file_path") or job.get("s3_key") or "Unknown Source File"
    
    # Serve HTML if browser
    if "text/html" in request.headers.get("accept", ""):
        def output_label(k):
            return {
                "extracted_text_path": "Extracted Text",
                "bpmn_template_path": "BPMN Template (JSON)",
                "refined_bpmn_template_path": "Refined BPMN Template (JSON)",
                "bpmn_xml_path": "BPMN XML (raw)",
                "final_bpmn_xml_path": "Final BPMN XML (.bpmn)",
                "summary_path": "Summary",
                "result_path": "Download Final BPMN"
            }.get(k, k)
        
        def is_bpmn(fname):
            return fname.endswith('.bpmn')
        
        def is_text(fname):
            return fname.endswith('.txt') or fname.endswith('.json') or fname.endswith('.xml')
        
        html = f"""
        <html><head><title>Job Outputs for {job_id}</title>
        <link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
        <style>
        body {{ font-family: sans-serif; }}
        .modal-bg {{ position:fixed;top:0;left:0;width:100vw;height:100vh;background:rgba(0,0,0,0.25);z-index:1000;display:flex;align-items:center;justify-content:center; }}
        .modal-content {{ background:#fff;border-radius:10px;padding:24px;min-width:320px;max-width:900px;max-height:90vh;overflow-y:auto;box-shadow:0 2px 16px #0002; }}
        .bpmn-viewer {{ width:800px;height:500px;background:#f6f8fa;border-radius:8px; }}
        .close-btn {{ background:#10a37f;color:#fff;border:none;border-radius:6px;padding:8px 18px;font-weight:500;cursor:pointer;margin-top:18px;float:right; }}
        .view-link {{ color:#10a37f;text-decoration:underline;font-weight:500;cursor:pointer; }}
        </style>
        <script src="https://unpkg.com/bpmn-js@11.5.0/dist/bpmn-viewer.development.js"></script>
        </head><body>
        <h2>Job Status: <span style='color:{'green' if status=='completed' else 'orange' if status=='processing' else 'red'}'>{status}</span></h2>
        <button onclick='window.location.reload()'>Refresh</button>
        <h3>Source File:</h3>
        <ul><li><b>{source_file}</b>
          <ul>
        """
        
        for k, v in outputs.items():
            fname = os.path.basename(v)
            label = output_label(k)
            if is_bpmn(fname):
                html += f"<li>{label} ({fname}) <span class='view-link' onclick=\"viewBpmn('/download/{job_id}/{k.replace('_path','')}','{fname}')\">[View]</span></li>"
            elif is_text(fname):
                html += f"<li>{label} ({fname}) <span class='view-link' onclick=\"viewText('/download/{job_id}/{k.replace('_path','')}','{fname}')\">[View]</span></li>"
            else:
                html += f"<li>{label} ({fname}) <a href='/download/{job_id}/{k.replace('_path','')}' target='_blank'>[Download]</a></li>"
        
        html += "</ul></li></ul>"
        html += """
        <div id='modal-bg' class='modal-bg' style='display:none' onclick='closeModal()'>
          <div id='modal-content' class='modal-content' onclick='event.stopPropagation()'>
            <div id='modal-title' style='font-weight:600;margin-bottom:12px'></div>
            <div id='modal-body'></div>
            <button class='close-btn' onclick='closeModal()'>Close</button>
          </div>
        </div>
        <script>
        function closeModal() {
          document.getElementById('modal-bg').style.display = 'none';
          document.getElementById('modal-title').innerHTML = '';
          document.getElementById('modal-body').innerHTML = '';
        }
        function viewText(url, fname) {
          fetch(url).then(r=>r.text()).then(txt=>{
            document.getElementById('modal-title').innerText = fname;
            let body = document.getElementById('modal-body');
            if(fname.endsWith('.json')) {
              try { txt = JSON.stringify(JSON.parse(txt), null, 2); } catch(e){}
            }
            body.innerHTML = `<pre style='white-space:pre-wrap;text-align:left;background:#f6f8fa;padding:16px;border-radius:8px;font-size:14px;'>${txt.replace(/</g,'&lt;')}</pre>`;
            document.getElementById('modal-bg').style.display = 'flex';
          });
        }
        function viewBpmn(url, fname) {
          fetch(url).then(r=>r.text()).then(xml=>{
            document.getElementById('modal-title').innerText = fname;
            document.getElementById('modal-body').innerHTML = `<div id='bpmn-viewer' class='bpmn-viewer'></div>`;
            document.getElementById('modal-bg').style.display = 'flex';
            setTimeout(()=>{
              var viewer = new window.BpmnJS({ container: '#bpmn-viewer' });
              viewer.importXML(xml).then(()=>{
                viewer.get('canvas').zoom('fit-viewport');
              });
            }, 100);
          });
        }
        </script>
        </body></html>
        """
        return HTMLResponse(html)
    
    # Default: JSON for API
    return {"outputs": outputs, "status": status}

@app.get("/results_structure")
def results_structure(current_user: str = Depends(get_current_user)):
    """Get the structure of all results in S3 with timestamps"""
    structure, timestamps = list_results_structure()
    
    # List all input files in S3 (excluding results/) with their timestamps
    import boto3
    s3_client = boto3.client('s3')
    response = s3_client.list_objects_v2(Bucket=S3_BUCKET)
    files = response.get("Contents", [])
    input_files = []
    input_file_timestamps = {}
    
    for obj in files:
        key = obj["Key"]
        if key.startswith("results/") or key.startswith("auth/") or key.endswith("/"):
            continue
        input_files.append(key)
        # Store the original file timestamp
        input_file_timestamps[key] = {
            "last_modified": obj.get("LastModified"),
            "size": obj.get("ContentLength")
        }
    
    return {
        "results": structure, 
        "input_files": input_files,
        "timestamps": timestamps,
        "input_file_timestamps": input_file_timestamps
    }

@app.get("/reprocessable_files")
def get_reprocessable_files(current_user: str = Depends(get_current_user)):
    """Get list of files that can be reprocessed (have existing results)"""
    try:
        structure, timestamps = list_results_structure()
        
        # Files that can be reprocessed are those that have results
        reprocessable_files = []
        
        for s3_key, outputs in structure.items():
            # Check if all expected outputs exist
            expected_outputs = [
                "bpmn_template.json",
                "bpmn_xml.xml", 
                "extracted_text.txt",
                "final_bpmn_xml.bpmn",
                "refined_bpmn_template.json",
                "result.bpmn.xml",
                "summary.txt"
            ]
            
            if all(output in outputs for output in expected_outputs):
                reprocessable_files.append({
                    "s3_key": s3_key,
                    "outputs_count": len(outputs),
                    "has_all_outputs": True
                })
            else:
                reprocessable_files.append({
                    "s3_key": s3_key,
                    "outputs_count": len(outputs),
                    "has_all_outputs": False,
                    "missing_outputs": [output for output in expected_outputs if output not in outputs]
                })
        
        return {
            "reprocessable_files": reprocessable_files,
            "total_files": len(reprocessable_files),
            "complete_files": len([f for f in reprocessable_files if f["has_all_outputs"]])
        }
        
    except Exception as e:
        print(f"[get_reprocessable_files] Error: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/results/{input_key:path}/{output_name}")
def serve_result_file(input_key: str, output_name: str, background_tasks: BackgroundTasks):
    """Serve result files from S3"""
    # input_key is the S3 key (may contain slashes)
    # output_name is the file name
    s3_key = f"results/{input_key}/{output_name}"
    
    # Download from S3 to temp file
    temp_file_path = os.path.join("/tmp", f"{input_key.replace('/', '_')}_{output_name}")
    try:
        # Download from S3
        import boto3
        s3_client = boto3.client('s3')
        s3_client.download_file(S3_BUCKET, s3_key, temp_file_path)
        
        # Check if this is a BPMN file that needs cleaning
        if output_name.endswith('.bpmn') or output_name.endswith('.xml'):
            try:
                with open(temp_file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # If content contains explanatory text, clean it
                if content.find('Certainly!') != -1 or content.find('**refined, deployment-ready BPMN 2.0 XML**') != -1:
                    clean_content = extract_xml_content(content)
                    content = clean_content
                    print(f"[serve_result_file] Cleaned BPMN file {output_name}")
                

                
                # Add watermark to BPMN files
                content = add_bpmn_watermark(content)
                
                # Write the watermarked content back to temp file
                with open(temp_file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"[serve_result_file] Added watermark to BPMN file {output_name}")
            except Exception as e:
                print(f"[serve_result_file] Error cleaning BPMN file {output_name}: {e}")
        
        # Add cleanup task to background
        def cleanup_temp_file():
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
        
        background_tasks.add_task(cleanup_temp_file)
        
        return FileResponse(temp_file_path, filename=output_name)
        
    except Exception as e:
        # Clean up temp file on error
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        print(f"[serve_result_file] Error downloading file {s3_key}: {e}")
        return JSONResponse(status_code=404, content={"error": "File not found"}) 

@app.get("/file_timestamps/{input_key}")
def get_file_timestamps(input_key: str):
    """Get detailed timestamp information for a specific file"""
    try:
        # Get the results structure and timestamps
        structure, timestamps = list_results_structure()
        
        # Get input file timestamp
        import boto3
        s3_client = boto3.client('s3')
        input_timestamp = None
        try:
            response = s3_client.head_object(Bucket=S3_BUCKET, Key=input_key)
            input_timestamp = response.get("LastModified")
        except:
            pass
        
        # Get output file timestamps
        output_timestamps = {}
        if input_key in structure:
            for output_name in structure[input_key]:
                s3_key = f"results/{input_key}/{output_name}"
                try:
                    response = s3_client.head_object(Bucket=S3_BUCKET, Key=s3_key)
                    output_timestamps[output_name] = {
                        "last_modified": response.get("LastModified"),
                        "size": response.get("ContentLength")
                    }
                except:
                    pass
        
        return {
            "input_key": input_key,
            "input_timestamp": input_timestamp,
            "output_timestamps": output_timestamps,
            "latest_processing": timestamps.get(input_key, {}).get("last_modified"),
            "files_count": timestamps.get(input_key, {}).get("files_count", 0)
        }
        
    except Exception as e:
        print(f"[get_file_timestamps] Error: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)}) 